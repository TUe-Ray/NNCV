import torch
import torch.nn as nn
from Model_Convnext_unet import ConvNeXtUNet

def count_parameters(model):
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“¦ ç¸½åƒæ•¸é‡ï¼š{total:,}")
    print(f"ğŸ§  å¯è¨“ç·´åƒæ•¸é‡ï¼š{trainable:,}")
    return total, trainable

def count_encoder_decoder_params(model):
    encoder_params = 0
    decoder_params = 0

    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue  # è·³éä¸éœ€è¦è¨“ç·´çš„åƒæ•¸
        if 'down' in name or 'enc' in name:
            encoder_params += param.numel()
        elif 'up' in name or 'dec' in name:
            decoder_params += param.numel()
    
    print(f"ğŸ“¥ Encoder åƒæ•¸é‡ï¼š{encoder_params:,}")
    print(f"ğŸ“¤ Decoder åƒæ•¸é‡ï¼š{decoder_params:,}")
    return encoder_params, decoder_params

# å»ºç«‹æ¨¡å‹
model = ConvNeXtUNet(in_channels=3, n_classes=19)

# çµ±è¨ˆæ•´é«”åƒæ•¸
print("ğŸ“Š æ¨¡å‹ç¸½åƒæ•¸çµ±è¨ˆï¼š")
count_parameters(model)

# çµ±è¨ˆ Encoder/Decoder
print("\nğŸ” Encoder/Decoder åƒæ•¸çµ±è¨ˆï¼š")
count_encoder_decoder_params(model)
